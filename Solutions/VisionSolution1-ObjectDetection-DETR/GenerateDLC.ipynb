{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94b4143-7c12-4f89-9b4f-459f053b6050",
   "metadata": {},
   "source": [
    "# Setting Up SDK Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1748bf-bc9a-4a9f-9ece-55dcfa54705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/local/mnt/workspace/snpe/2.29.0.241129\" #set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['DLC32']=\"models/detr_resnet101_fp32.dlc\"  # Use the path to your non-quantized dlc\n",
    "os.environ['DLC8']=\"models/detr_resnet101_w8a8.dlc\"              # Use the path to your Quantized dlc\n",
    "os.environ['TARGET_INPUT_LIST']=\"list.txt\"  # Use the name of the input file\n",
    "os.environ['ONDEVICE_FOLDER']=\"detr\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"728b7a92\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v79\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140a00d-4a8e-419b-975a-a6a6810ac76e",
   "metadata": {},
   "source": [
    "## Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd0a42-b02b-4013-88f3-8e417729c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet101', pretrained=True)\n",
    "model.eval()\n",
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "output = model(dummy_input)\n",
    "print(output['pred_logits'].shape)\n",
    "\n",
    "class ModifiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "    def forward(self,pixel_values):\n",
    "        output = self.model(pixel_values)\n",
    "        output['pred_logits'] = output['pred_logits'].softmax(-1)[0,:,:-1]\n",
    "        return output\n",
    "customModel = ModifiedModel()\n",
    "customModel.eval()\n",
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "output = customModel(dummy_input)\n",
    "print(output['pred_logits'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450758bd-a367-4d2c-9bb0-d2ea60704f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05945e74-19fc-4f96-8fc3-a938769db6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "\n",
    "torch.onnx.export(customModel, dummy_input, \"models/detr_resnet101.onnx\", opset_version=11\n",
    "                  , verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0d26e-d0b2-413f-99d9-fb9488edf021",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc --input_network models/detr_resnet101.onnx --output_path models/detr_resnet101_fp32.dlc\n",
    "snpe-dlc-info -i models/detr_resnet101_fp32.dlc > models/detr_resnet101_fp32.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6259dc-4d98-4358-8456-1ea9e353f192",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5270dc-c0c9-4e3f-8403-5ed4f92b66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "torch.set_grad_enabled(False);\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch.nn.functional as nnf\n",
    "import subprocess\n",
    "!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289295b0-7a9b-4de6-a02b-9435acf52897",
   "metadata": {},
   "source": [
    "## Getting the Dataset and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d07d1-8210-480d-bec3-746e21c4c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can download dataset of their choice for accuracy validation. \n",
    "# User needs to follow the pre/post processing steps prescribed in dataset (or) given below. \n",
    "# You can use coco val2017 or part of it.\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip -q --show-progress\n",
    "!unzip val2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58058123-6a1a-4cb0-a836-030ac644cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('val2017') #val2017 is the datatset folder path. Keeping only 15 images.\n",
    "for file in files[15:]:\n",
    "    os.remove(\"val2017/\"+file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33306686-36f1-4063-a2d9-4adc170f7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf val2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e581c6c-3fe2-493a-a99f-26feda92c17b",
   "metadata": {},
   "source": [
    "### Pre-Processing Steps of DETR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb6093-42b4-45c2-8c3e-d12d22d6381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def plot_results(pil_img, prob, boxes,Image_count):\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    ax1=fig.add_subplot(2,2,3)\n",
    "    ax1.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=1))\n",
    "        cl = p.argmax()\n",
    "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=10,\n",
    "                bbox=dict(alpha=0.5))\n",
    "    plt.savefig(str(Image_count)+\".jpg\")\n",
    "    if Image_count%2==0:\n",
    "        shutil.move(str(Image_count)+\".jpg\",\"output/CPU\")\n",
    "    else:\n",
    "        shutil.move(str(Image_count)+\".jpg\",\"output/DSP\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8c1b1-55b7-4cd5-b26a-cf17d737e1ae",
   "metadata": {},
   "source": [
    "### Steps to create raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b0aba-9d06-4f91-98d5-4a17b2127c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"raw\"\n",
    "os.system('mkdir ' + name)\n",
    "def detect(imgfile,i):\n",
    "    #getting the actual image\n",
    "    origimg = Image.open(imgfile)\n",
    "    #Transforming the image\n",
    "    img = transform(origimg).unsqueeze(0)\n",
    "\n",
    "    img= nnf.interpolate(img, size=(800, 1066), mode='bicubic', align_corners=False)\n",
    "    \n",
    "    img_to_save=img.numpy().transpose(0,2,3,1).astype(np.float32)\n",
    "    \n",
    "    img_to_save.tofile(\"raw/\"+filenames[i].split(\".\")[0]+\".raw\")\n",
    "    \n",
    "filenames = os.listdir(\"val2017\") ## change val2017 to the folder name where you have your dataset images.\n",
    "for i in range(0,len(filenames)):\n",
    "    if \"jpg\" in filenames[i].lower():\n",
    "        detect(\"val2017/\"+filenames[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992e8ce-c6df-4169-979e-b000e7943fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find ./raw -name *.raw > list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57404ad6-9bcf-4254-9ae7-902e34b80196",
   "metadata": {},
   "source": [
    "### Getting the Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6d39d-06ce-4c5b-a5c5-1a08a51fd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-quantize --input_dlc models/detr_resnet101_fp32.dlc --input_list list.txt  --output_dlc models/detr_resnet101_w8a8.dlc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef45dba-afcd-4843-83b2-cf6be8b6f1f6",
   "metadata": {},
   "source": [
    "- For snpe-dlc-graph-prepare fix value of htp_soc.\n",
    "- Based on the device you will be running set value of <b>--htp_socs. Example sm8750 or sm8650 or sm8550</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7cb043-00b2-49c5-9368-60845ebb7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-graph-prepare --input_dlc models/detr_resnet101_w8a8.dlc --htp_socs=sm8750 --set_output_tensors=5848,5856 --output_dlc=models/detr_resnet101_w8a8_cached.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8561ebf-c06a-4602-9136-84dfde6813d7",
   "metadata": {},
   "source": [
    "**Optional Code blocks**\n",
    "## Creating Bin and Lib Folder On Device\n",
    "\n",
    "<b>- Below blocks are completely optional. \n",
    "- You have the model already prepared.\n",
    "- Run below code blocks only if you want to try out model by pushing it device.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7817b-0574-48b6-8c8e-3184f1ca93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#source throughput.sh >>dump.txt\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb8d16-46a7-46fc-835b-0bb53b1a5a66",
   "metadata": {},
   "source": [
    "# Pusing All Bin and Lib Files on to Device\n",
    "* use hexagon-v79 for sm8750\n",
    "* use hexagon-v75 for sm8650\n",
    "* use hexagon-v73 for sm8550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c5228-fb41-4ba7-b1bf-b1b258dadcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v79/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c7322-6293-45ba-84b0-f48ff22edb67",
   "metadata": {},
   "source": [
    "# Pushing Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297e7ac-dace-4d31-9fbf-e3829843f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44ca30-4fd9-48a8-a3c5-a735a90defd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $RAW_FILE_FOLDER /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC32 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push models/detr_resnet101_w8a8_gp.dlc /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC8 /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45da446-097d-452e-b9bf-289128391982",
   "metadata": {},
   "source": [
    "# Inferencing 8-bit DLC onto DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d6786-6fd5-4860-8159-e5729d405e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export SNPE_TARGET_ARCH=aarch64-android\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_8b_DSP\n",
    "export DLC8=detr_resnet101_w8a8_gp.dlc\n",
    "export ONDEVICE_FOLDER=\"detr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "chmod -R 777 * &&\n",
    "snpe-net-run --container $DLC8 --input_list list.txt  --set_unconsumed_as_output --output_dir=OUTPUT_8b_DSP --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e8fed-d3af-4938-b3fb-79d7ffe93b79",
   "metadata": {},
   "source": [
    "# Inferencing 32-bit DLC onto CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670f413-3cb2-4fd6-8592-ab5b787b47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export SNPE_TARGET_ARCH=aarch64-android\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export DLC32=detr_resnet101_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"detr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC32 --input_list list.txt  --output_dir=OUTPUT_32b_CPU --set_unconsumed_as_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f272d-4641-4f89-b622-6ab769af29d8",
   "metadata": {},
   "source": [
    "# Pulling output folder generated on different Precision and Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744d5da-3c50-47c6-b354-ff878cc58288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_8b_DSP OUTPUT_8b_DSP\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a41e6-cb53-4a48-ad3f-847432495928",
   "metadata": {},
   "source": [
    "## Post Processing the Inferenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9b2db-7b39-4a2c-8dda-b3ac55206e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample list of classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ba131-f92b-4538-a884-e7d7029283d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Image_Paths=[]\n",
    "\n",
    "with open('list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        Image_Paths.append(line.strip().split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "count=Image_count=0\n",
    "if os.path.exists(\"output\")==False:\n",
    "    os.mkdir(\"output\")\n",
    "if os.path.exists(\"output/CPU\")==False:\n",
    "    os.mkdir(\"output/CPU\")\n",
    "if os.path.exists(\"output/DSP\")==False:\n",
    "    os.mkdir(\"output/DSP\")\n",
    "for image in Image_Paths:\n",
    "    image_path = 'val2017/'+image+\".jpg\"\n",
    "    im = Image.open(image_path)\n",
    "    file1 = 'OUTPUT_32b_CPU/Result_' + str(count) + '/5867.raw'\n",
    "    file2 = 'OUTPUT_32b_CPU/Result_' + str(count) + '/5860.raw'\n",
    "    file3 = 'OUTPUT_8b_DSP/Result_' + str(count) + '/5867.raw'\n",
    "    file4 = 'OUTPUT_8b_DSP/Result_' + str(count) + '/5860.raw'\n",
    "    a=np.fromfile(file1,np.float32)\n",
    "    a=a.reshape(100,91)\n",
    "    tensor_a = torch.from_numpy(a)\n",
    "    b=np.fromfile(file2,np.float32)\n",
    "    b=b.reshape(1,100,4)\n",
    "    tensor_b = torch.from_numpy(b)\n",
    "\n",
    "    c=np.fromfile(file3,np.float32)\n",
    "    c=c.reshape(100,91)\n",
    "    tensor_c = torch.from_numpy(c)\n",
    "    d=np.fromfile(file4,np.float32)\n",
    "    d=d.reshape(1,100,4)\n",
    "    tensor_d = torch.from_numpy(d)\n",
    "\n",
    "\n",
    "    \n",
    "    probas = tensor_a\n",
    "    keep = probas.max(-1).values > 0.9\n",
    "    bboxes_scaled = rescale_bboxes(tensor_b[0, keep], im.size)\n",
    "    print(\"CPU FP32 Inference Result\")\n",
    "    plot_results(im, probas[keep], bboxes_scaled,Image_count)\n",
    "    Image_count=Image_count+1\n",
    "\n",
    "    probas = tensor_c\n",
    "    keep = probas.max(-1).values > 0.9\n",
    "    bboxes_scaled = rescale_bboxes(tensor_d[0, keep], im.size)\n",
    "    print(\"DSP INT8 Inference Result\")\n",
    "    plot_results(im, probas[keep], bboxes_scaled,Image_count)\n",
    "    Image_count=Image_count+1\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0e3a6-c33d-4320-b61d-e224c85e6438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83386c6f-7c23-4bfb-af4e-8e91d90e129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
