{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039733ac-47fb-4ab3-a842-1013a2e1dea3",
   "metadata": {},
   "source": [
    "# Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28e659-dd04-4f14-9a04-c8fbf3f0e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give appropriate permission to the directory \"FOLDER_WITH_ARTIFACTS\" you are working with\n",
    "import os\n",
    "os.environ['QNN_SDK_ROOT']=\"/local/mnt/workspace/qairt/2.40.0.251030\"#set up your snpe path here.\n",
    "os.environ['ANDROID_NDK_ROOT']=\"/usr/android-ndk-r26c\"\n",
    "os.environ['QNN_TARGET_ARCH']=\"aarch64-android\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beb449e3-2ff5-43b8-84c9-0f92c70a76b0",
   "metadata": {},
   "source": [
    "####  Any issue with circular import error while importing super_gradients. To overcome this make the below changes ####\n",
    "In your python enviroment, update super gradients package (3.1.2) package as shown below\n",
    "\n",
    "***Code change 1#***\n",
    "In /usr/venv/lib/python3.10/site-packages/super_gradients/training/\\_\\_init\\_\\_.py\n",
    "\n",
    "**Existing Code**: import super_gradients.training.utils.distributed_training_utils as distributed_training_utils \n",
    "\n",
    "**Modify**: from .utils import distributed_training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7c3bb-9f35-4d1c-84b7-c5de30ec895e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Note- Use python3.8 or above for generating onnx\n",
    "# !pip install super-gradients==3.1.2 ### Uncomment and run it if you haven't installed it before\n",
    "import torch\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228d5e0-beb1-4033-be62-165dcdd3bd02",
   "metadata": {},
   "source": [
    "## Getting the ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb32d9-064e-428e-bb3e-270765df79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a8e9b-57b1-4cfe-98b1-b5f6649c41d5",
   "metadata": {},
   "source": [
    "### YOLO_NAS_S Model has issues while download. To overcome, follow below steps:\n",
    "In your python enviroment, update super gradients package (3.1.2) with the modified YOLO_NAS_S download link.\n",
    "\n",
    "***Code Change 1#***:\n",
    "In /usr/venv/lib/python3.10/site-packages/super_gradients/training/pretrained_models.py line 47\n",
    "\n",
    "**Existing Code**: \"yolo_nas_s_coco\": \"https://sghub.deci.ai/models/yolo_nas_s_coco.pth\",\n",
    "\n",
    "**Modify**: \"yolo_nas_s_coco\": \"https://sg-hub-nv.s3.amazonaws.com/models/yolo_nas_s_coco.pth\",\n",
    "\n",
    "***Code Change 2#***:\n",
    "In /usr/venv/lib/python3.10/site-packages/super_gradient/training/utils/checkpoint_utils.py line 316, Function Name:load_pretrained_weightsline\n",
    "\n",
    "**Existing code**: unique_filename = url.split(\"https://sghub.deci.ai/models/\")[1].replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "**Modify**: unique_filename = url.split(\"https://sg-hub-nv.s3.amazonaws.com/models/\")[1].replace(\"/\", \"_\").replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6522d80-61d2-47df-a84a-69cf802dc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")\n",
    "# Prpare model for conversion\n",
    "# Input size is in format of [Batch x Channels x Width x Height] where 640 is the standard COCO dataset dimensions\n",
    "model.eval()\n",
    "model.prep_model_for_conversion(input_size=[1, 3, 320, 320])\n",
    "# Create dummy_input\n",
    "dummy_input = torch.randn([1, 3, 320, 320], device=\"cpu\")\n",
    "# Convert model to onnx\n",
    "torch.onnx.export(model, dummy_input, \"models/yolo_nas_s.onnx\", opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672610a-f036-4fab-8837-2d83dbe051b7",
   "metadata": {},
   "source": [
    "#### Getting the FP32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce77df-5e7c-4bcc-896c-023eec610993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "export PATH=${ANDROID_NDK_ROOT}:${PATH}\n",
    "qnn-onnx-converter --input_network models/yolo_nas_s.onnx --output_path output_cpu/yolo_nas_s.cpp --out_node 885 --out_node 877\n",
    "qnn-model-lib-generator -c output_cpu/yolo_nas_s.cpp -b output_cpu/yolo_nas_s.bin --output_dir output_cpu/ -t aarch64-android\n",
    "mv output_cpu/aarch64-android/libyolo_nas_s.so  output_cpu/aarch64-android/libyolo_nas_w8a8.so "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c026e-70db-4ec4-8572-104d09155716",
   "metadata": {},
   "source": [
    "### Getting The dataset\n",
    "Please, fill coco dataset link in below code block. You might need 10-15 images for quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1143dd-d689-4139-a853-d7fd3f71c96b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/zips/val2017.zip -q --show-progress\n",
    "!unzip val2017.zip\n",
    "!mkdir \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc29d5-3c7e-47c7-87f7-781cd0f84685",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('val2017') #val2017 is the datatset folder path. Keeping only 15 images.\n",
    "for file in files[15:]:\n",
    "    os.remove(\"val2017/\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e09a04-a022-4efd-abb0-96d3f72e48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf val2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266ceff-55eb-499e-a52b-a6269f137086",
   "metadata": {},
   "source": [
    "#### Getting the Quatized Model for DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f742fe-106f-4640-9340-d377161196b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess(original_image):\n",
    "    resized_image = cv2.resize(original_image, (320, 320))\n",
    "    resized_image = resized_image/255\n",
    "    return resized_image\n",
    "\n",
    "##Please download Coco2014 dataset and give the path here\n",
    "dataset_path = \"val2017/\"\n",
    "\n",
    "filenames=[]\n",
    "for path in os.listdir(dataset_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dataset_path, path)):\n",
    "        filenames.append(os.path.join(dataset_path, path))\n",
    "        \n",
    "for filename in filenames:\n",
    "    original_image = cv2.imread(filename)\n",
    "    img = preprocess(original_image)\n",
    "    img = img.astype(np.float32)\n",
    "    img.tofile(\"raw/\"+filename.split(\"/\")[-1].split(\".\")[0]+\".raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba98192-654d-4d3d-9290-204ef71e33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find raw -name *.raw > input.txt\n",
    "cat input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd9020-e7ad-48fa-b72c-63f2dc5f53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "export PATH=${ANDROID_NDK_ROOT}:${PATH}\n",
    "qnn-onnx-converter --input_network models/yolo_nas_s.onnx --output_path output_dsp/yolo_nas_s_quantized.cpp --out_node 885 --out_node 877 --input_list input.txt \n",
    "qnn-model-lib-generator -c output_dsp/yolo_nas_s_quantized.cpp -b output_dsp/yolo_nas_s_quantized.bin --output_dir output_dsp/ -t aarch64-android\n",
    "mv output_dsp/aarch64-android/libyolo_nas_s_quantized.so  output_dsp/aarch64-android/libyolo_nas_w8a8_dsp.so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff14b23-d5fb-49bf-a227-66d13374893e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
