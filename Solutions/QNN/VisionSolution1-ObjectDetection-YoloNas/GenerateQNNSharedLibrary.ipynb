{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039733ac-47fb-4ab3-a842-1013a2e1dea3",
   "metadata": {},
   "source": [
    "# Setting Up All Artifacts details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28e659-dd04-4f14-9a04-c8fbf3f0e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give appropriate permission to the directory \"FOLDER_WITH_ARTIFACTS\" you are working with\n",
    "import os\n",
    "os.environ['QNN_SDK_ROOT']=\"/local/mnt/workspace/snpe/2.25.0.240728\"#set up your snpe path here.\n",
    "os.environ['ANDROID_NDK_ROOT']=\"/usr/android-ndk-r26c\"#set up your snpe path here.\n",
    "os.environ['QNN_TARGET_ARCH']=\"aarch64-android\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7c3bb-9f35-4d1c-84b7-c5de30ec895e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Note- Use python3.8 or above for generating onnx\n",
    "!pip install super-gradients==3.1.2\n",
    "import torch\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228d5e0-beb1-4033-be62-165dcdd3bd02",
   "metadata": {},
   "source": [
    "## Getting the ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb32d9-064e-428e-bb3e-270765df79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6522d80-61d2-47df-a84a-69cf802dc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\")\n",
    "# Prpare model for conversion\n",
    "# Input size is in format of [Batch x Channels x Width x Height] where 640 is the standard COCO dataset dimensions\n",
    "model.eval()\n",
    "model.prep_model_for_conversion(input_size=[1, 3, 320, 320])\n",
    "# Create dummy_input\n",
    "dummy_input = torch.randn([1, 3, 320, 320], device=\"cpu\")\n",
    "# Convert model to onnx\n",
    "torch.onnx.export(model, dummy_input, \"models/yolo_nas_s.onnx\", opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672610a-f036-4fab-8837-2d83dbe051b7",
   "metadata": {},
   "source": [
    "#### Getting the FP32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce77df-5e7c-4bcc-896c-023eec610993",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "export PATH=${ANDROID_NDK_ROOT}:${PATH}\n",
    "qnn-onnx-converter --input_network models/yolo_nas_s.onnx --output_path output_cpu/yolo_nas_s.cpp --out_node 885 --out_node 877\n",
    "qnn-model-lib-generator -c output_cpu/yolo_nas_s.cpp -b output_cpu/yolo_nas_s.bin --output_dir output_cpu/ -t aarch64-android"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266ceff-55eb-499e-a52b-a6269f137086",
   "metadata": {},
   "source": [
    "#### Getting the Quatized Model for DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc29d5-3c7e-47c7-87f7-781cd0f84685",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f742fe-106f-4640-9340-d377161196b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess(original_image):\n",
    "    resized_image = cv2.resize(original_image, (320, 320))\n",
    "    resized_image = resized_image/255\n",
    "    return resized_image\n",
    "\n",
    "##Please download Coco2014 dataset and give the path here\n",
    "dataset_path = \"images/\"\n",
    "\n",
    "filenames=[]\n",
    "for path in os.listdir(dataset_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dataset_path, path)):\n",
    "        filenames.append(os.path.join(dataset_path, path))\n",
    "        \n",
    "for filename in filenames:\n",
    "    original_image = cv2.imread(filename)\n",
    "    img = preprocess(original_image)\n",
    "    img = img.astype(np.float32)\n",
    "    img.tofile(\"raw/\"+filename.split(\"/\")[-1].split(\".\")[0]+\".raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba98192-654d-4d3d-9290-204ef71e33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find raw -name *.raw > input.txt\n",
    "cat input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd9020-e7ad-48fa-b72c-63f2dc5f53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "export PATH=${ANDROID_NDK_ROOT}:${PATH}\n",
    "qnn-onnx-converter --input_network models/yolo_nas_s.onnx --output_path output_dsp/yolo_nas_s_quantized.cpp --out_node 885 --out_node 877 --input_list input.txt \n",
    "qnn-model-lib-generator -c output_dsp/yolo_nas_s_quantized.cpp -b output_dsp/yolo_nas_s_quantized.bin --output_dir output_dsp/ -t aarch64-android\n",
    "mv output_dsp/aarch64-android/libyolo_nas_s_quantized.so  output_dsp/aarch64-android/libyolo_nas_w8a8_dsp.so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36ac68-f1c1-4f3e-b635-21aaf07e4d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
